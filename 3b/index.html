<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>CS180 Project 3B: IMAGE WARPING and MOSAICING</title>
  <style>
    body {
      font-family: Arial, sans-serif;
      margin: 40px;
      line-height: 1.6;
    }
    h1, h2, h3 {
      margin-top: 40px;
    }
    h2 {
      border-bottom: 2px solid #ccc;
      padding-bottom: 5px;
    }
    .section {
      margin-bottom: 50px;
    }
    .image-row {
      display: flex;
      justify-content: center;
      gap: 20px;
      margin-top: 20px;
      flex-wrap: wrap;
    }
    .image-container {
      text-align: center;
      max-width: 30%;
    }
    .image-container img {
      width: 100%;
      height: auto;
      border: 1px solid #ccc;
    }
    .full-width-image {
      width: 60%;
      max-width: 70%;
      margin: 20px 0;
      text-align: center;
    }

    .full-width-image img {
      width: 100%;      /* scale to fit screen width */
      height: auto;     /* maintain aspect ratio */
      display: block;
      margin: 0 auto;
      border: 1px solid #ccc;
      max-width: 100%;  /* ensure it doesn’t overflow container */
    }

    .full-width-image .grid-caption {
      margin-top: 8px;
      font-size: 0.9em;
      color: #555;
    }

    .caption {
      margin-top: 8px;
      font-size: 0.9em;
      color: #555;
    }
    .grid {
      display: grid;
      grid-template-columns: repeat(3, 200px); /* fixed column width */
      gap: 20px;
      margin: 20px auto;         /* center the grid */
      justify-content: center;   /* center grid items */
    }

    .grid img {
      width: 100%;      /* force image to fit column */
      max-width: 200px; /* don’t let it stretch bigger */
      height: auto;     /* keep aspect ratio */
      object-fit: contain; /* shrink properly inside cell */
      border: 1px solid #ccc;
    }
    .grid-caption {
      text-align: center;
      margin-top: 6px;
      font-size: 0.9em;
      color: #555;
    }
    code {
      background-color: #efe0bf;
      padding: 2px 4px;
      border-radius: 4px;
      font-size: 0.95em;
    }
    .stack-image {
      display: block;
      margin: 20px auto;   /* center each one vertically stacked */
      max-width: 800px;    /* or whatever width you want */
      width: 100%;         /* scale down responsively */
      height: auto;        /* keep aspect ratio */
      border: 1px solid #ccc;
    }
    .stack-caption {
      text-align: center;
      margin-top: 8px;
      font-size: 0.9em;
      color: #555;
    }

  </style>
</head>
<body>

  <h1>CS180 Project 3B: Feature Matching for Autostitching</h1>

  <!-- Part 1 -->
  <div class="section">

    <h3>B.1 - Harris Corner Detection</h3>
    <p>
      When I first ran Harris Corner Detection on this image, I was worried that a lot of the selected corners were not in fact signifcant corners, and it seemed to span across the entire image. However, I still noticed that many of the corners did lie around the main subject of the image, which would help in future feature detection.
    </p>

    <p>
      I also experimented with different values for min_distance, and I found that increasing this value helped to spread out the corners evenly across the imge, but it did not get rid of the less significant ones in the background. It seemed that the only way to filter the insiginifcant corners successfully was with ANMS.
    </p>

    <div class="full-width-image">
      <img src="./out/harris1.png" alt="Orange Laplacian stack">
      <div class="grid-caption">Harris Corner Detection</div>
    </div>
    <h4>  
      Harris Detection with ANMS
    </h4>
    <p>
      After implementing ANMS, I was able to significantly reduce the number of detected corners while maintaining a good distribution across the image. This helped in selecting the most prominent features and removed most of the features in the background where the fog and sky is.
    </p>
    <div class="full-width-image">
      <img src="./out/anms1.png" alt="Orange Laplacian stack">
      <div class="grid-caption"></div>
    </div>
    <div class="full-width-image">
      <img src="./out/anms2.png" alt="Orange Laplacian stack">
      <div class="grid-caption"></div>
    </div>
    <p>
      Additionally, I was happy to see that a lot of the filtered corners across both images seemed to concentrate around the same areas, which would also help in future feature matching because it limits the set of features that could be the same in both images to only the similar ones in location in both images.
    </p>

    <h3>B.2 - Feature Descriptor Extactor</h3>


    <p>
To do this, I iterated though each of the filtered corners from ANMS and extracted a 40x40 pixel patch around each corner. Then, I resized the patch using cv2.resize to an 8x8 pixel patch, which I then flattened into a 64-dimensional vector. Finally, I normalized the vector to have zero mean and unit variance to ensure that the descriptors were invariant to lighting changes.
    </p>
    <p>
      I repeated this process for both image1 and image2.
    </p>

    <div class="full-width-image">
        <img src="./out/features1.png" alt="Orange Laplacian stack">
        <div class="grid-caption">Extracted Features from Image1</div>
    </div>
    <div class="full-width-image">
        <img src="./out/features2.png" alt="Orange Laplacian stack">
        <div class="grid-caption">Extracted Features from Image2</div>
    </div>
    

    
    
    
    <h3>B.3 - Feature Matching</h3>
    <p>
      For the feature matching, I iterated through each feature descriptor and identified its 2 nearest neighbors in the other image using Lowe's ratio test, and was able to set a threshold of 0.7 for this image that filtered out most bad matches. Then I displayed the matches across both images, and adjusted the parameters to get a good number of accurate matches.
    </p>
    
    <div class="full-width-image">
        <img src="./out/matching.png" alt="Orange Laplacian stack">
        <div class="grid-caption">Warping with Bilinear Interpolation</div>
    </div>
  </div>
    <h3>B.4 - Mosaics Results</h3>
    <p>
      Using my mask and mosiac blending implementation from part 3A, I was able to use the created homography matrix to warp and blend my two images in Mountain Tamalpais, and it seemed that everything worked out, since the only thing I really changed was the values of the homography matrix H. 
     </p>

     <p>
      I then used the same process on another set of images of Kresge Library, and they also seemed to blend well using the same threshold, c, and min_distance values as the Mountain Tamalpais image.
     </p>

    <p>
      
    </p>


    <div class="full-width-image">
        <img src="./out/tam_blend.jpg" alt="Orange Laplacian stack">
        <div class="grid-caption">Mountain Tamalpais</div>
    </div>
    <div class="full-width-image">
        <img src="./out/kresge_blend.jpg" alt="Orange Laplacian stack">
        <div class="grid-caption">Kresge Library</div>
    </div>

    <p>
      However, when I tried to use the same process on the coffee shop image sets I used in part A of the project, the automatic feature matching did not work well, and the images were misaligned significantly. I tried to lower the threshold min_distance values, which reduced the blurring in the blending, but it still did not compare to the manual stitching mosiac result from part A. I believe that the automatic feature matching simply did not find good enough corresponding points and features perhaps due to how busy the image was, while with the manual selection, I was able to pick out the best points to align the images well.
    </p>
    <div class="full-width-image">
        <img src="./out/coffee_blend.jpg" alt="Orange Laplacian stack">
        <div class="grid-caption">Coffee Shop Blend with Automatic Stitching</div>
    </div>
    <div class="full-width-image">
        <img src="./out/coffee_blend_manual.jpg" alt="Orange Laplacian stack">
        <div class="grid-caption">Coffee Shop Blend with MANUAL Stitching</div>
    </div>
  
</body>
</html>
